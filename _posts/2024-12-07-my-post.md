---
layout: post
title: Lab 2
comments: true
mathjax: true

---

## Introduction

During this lab, my goal was to query the World Bank API and extract values such as the population and GDP per capita of a country. Initially, I was tasked with querying the World Bank API for the life expectancy, GDP per capita, and population of a country. However, I expanded upon these indicators and also decided to query the API for several other indicators, such as labor force, government expenditure on education, food production index, population growth, and access to electricity. I didn't just randomly choose these indicators, though. I chose to look into the labor force as it is an important part of a country's economy and ability to produce, I chose to look into government expenditure on education as this is a key factor in determining if the population is educated or not, I chose to look into the food production index as it can tell me if the country has a strong agricultural output, I chose to look into population growth as it is an important indicator in determining if a country is growing, and lastly, I chose to look into a country's access to electricity as this can determine if a country is impoverished, or underdeveloped. These are all important things to look at when trying to understand a country's economic or general state.

# Filtering

### Countries

There are a lot of countries to query in the World Bank API, however not all of the country's have the data for the indicators you choose. Some NA's will occasionally appear in your data, however its not the end of the world. Personally, I did filter out the country's that had NA for some of the indicators I chose as that would decrease the size of my dataset drastically, however if you wanted to really clean the data you produce you could filter out any countrys that have an NA for a given indicator. This can be done as shown:

```python
import pandas as pd

df = pd.read_csv("data.csv")

cleaned_df = df.dropna()

cleaned_df.to_csv('cleaned_file.csv', index=False)
print(cleaned_df)
```
By doing this to your data, you will get rid of any country's that returned NA for any of your indicators.

If you dont want to make a CSV for all the data you have extracted, you can also just go into the get_all_countries method and add a parameter that will exclude any countries you chose. You can make a list of countries you would like to exclude. This can be done by adding the following code:

```python
def get_all_countries():
        exclude_countries = ["Albania", "Afghanistan"]  
        BASE_URL = "http://api.worldbank.org/v2/country"
        params = {
            "format": "json",
            "per_page": 300
        }
        response = requests.get(BASE_URL, params=params)
        if response.status_code == 200:
            data = response.json()
            if data and len(data) > 1:
                return [
                    {"name": country["name"], "iso3": country["id"]}
                    for country in data[1]
                    if country["region"]["value"] != "Aggregates" and
                        (exclude_countries is None or country["name"] not in exclude_countries)
                ]
        return []
```

This should exclude any countries you want.

Additionally, this code excludes or filters out any aggregates, which refer to a group or collection of countries or regions that are combined into a single entity.

After applying the drop.na function to my csv I did lose quite a few countries. I removed any country that had None as a value for any indicator, this would prove helpful later on in the lab when using Ms. Feng's API.

### Years

During the lab, I did not need to filter out any years. If there was data for certain years that just had a bunch of Nones for the indicators, I used the drop.na() function to deal with any of these rows.

### Querying the API

While querying the API I noticed that the default number of results per page is limited to 50. How did I figure this out? I went to google and actually typed in the endpoint for a random indicator and country and checked how many results were displayed per page. However, by adding this line of code to the parameters of your API call, you can change this:

```python

"per_page": 300

```

By adding this line I have now made it so that 300 results are displayed per page. Of course you can change this value to whatever you want.

### Guaranteeing full coverage of results

If you want to guarantee full coverage of results while paginating through an API, you need to iterate through all available pages of data until no more results are returned. I wrote some code to achieve this. I did not utilize this portion of code in my main code, however I did test this in a seperate file to see how well it works. This is the code:

```python

import requests

def fetch_all_results(base_url, endpoint, params, headers):

    all_results = []
    page = 1
    while True:
        params['page'] = page 
        response = requests.get(f"{base_url}{endpoint}", params=params, headers=headers)

        if response.status_code != 200:
            raise Exception(f"API request failed {response.status_code}: {response.text}")

        data = response.json()
        if not data: 
            break

        all_results.extend(data)  
        page += 1  # Move to the next page

    return all_results


```

This function, fetch_all_results, basically ensures full coverage of paginated API results by iteratively requesting data from each page until no more results are returned. It collects and combines all the results into a single list, guaranteeing that no data is missed. This proved to be an efficient fix.

### Problems with my CSV and Ms. Feng's API

This step was by far the hardest for me. Initially I was able to print our all my CountryYear objects out in a list format. This was great and all however I need the individual values for each indicator from each country in a single list which acts as the column_a and column_b variable. In order to do this I took the whole list I printed out and threw it into a csv file with the appropriate column names. Then using the pandas library, I wrote this code to access the values for each column + convert them into a list:

```python

col_a = dataframe['life_expectancy'].tolist()  
col_b = dataframe['access_to_electricity'].tolist()  

```

This simple line of code would get me all the values I need to input into the API. However I ran into the same error for 2 days in a row until finally I solved it. This error was the following:

```python
KeyError: 'life_expectancy'
```

At first I didnt understand the issue, however this apparently meant that the column name didnt exist. How could that be possible? I went into the csv I had created and took a look at the column names. They all looked correct to me. There were no spelling errors or anything else out of the ordinary. But then I realised, there were extra spaces after each column name. I removed these spaces and there it was, all fixed. I cant believe this took my 2 days to figure out. 

While I was at it I also wanted to make sure the None values werent affecting me, so I checked the uncleaned.csv file I had which contained the Nones and the cleaned.csv which had all the countries with Nones removed. Turns out the file with nones are out of range float values are not JSON compliant. So it was important that all the None values were removed. The cleaned.csv worked perfectly fine with all the removed None values.

### Ms. Feng's API and P-values

So, I decided to test a couple of pairs of indicators and see the correlation between them. First I tested life_expectancy and access_to_electricity. I thought this would be a good pair to test as someone's ability to access electricity can make a large difference in their quality of life. Access to electricity means this person can have access to heaters, lights, the internet, etc. A lot of these things can determine the survival rate of people meaning it can very much affect the life_expectancy of a person. After using Ms. Feng's API to get a p-value to see if there is a significant correlation between the two I got a value of 0.0. Although this may seem very low and suspicious, it could also mean that there is a highly significant correlation between the two indicators, as any p-value below 0.05 is considered significant. 

Next I decided to test the GDP_per_capita against the labor_force as in order for a country to have a strong output, I think they should have a large labor_force that helps produce this output. However after passing my values into the API I received a p-value of 0.705470286895495 which is really high and indicates that there is no significant correlation between the two.

Next I tested government_expenditure_on_education against life_expectancy because I believe that if a person has a good education that will increase their life_expectancy as it opens more doors for a person in terms of jobs, careers, etc. And if a person can obtain a good job or have a good career this should increase their ability to make money and survive in harsh economies. After passing the values into the API I recieved a p-value of 0.0011005767749299178 which means there is a significant correlation between the two indicators.

lastly I tested food_production_index against population_growth, as in order for a population to grow it needs to produce enough food to feed its current population and future generations which are the offspring of the current population. After testing the correlation between the two indicators using the API I recieved a p-value of 0.07613287264264201, which isnt horrible but it means that the correlation is not that significant. Still signficant but not as significant as something below 0.05.

### Conclusion

Overall this lab taught me to always make sure that I have cleaned my data, and have double checked column names for spaces. Additionally I have learned to efficiently paginate through an API and gather lots of data on different countries. Lastly I enjoyed testing the correlations between different indicators as it sort of verified my initial thoughts about what I thought the correlation might be.

